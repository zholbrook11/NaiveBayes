{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080f0958-2da6-4d0e-b41c-6a5715ba2e93",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ecca972-5b9a-4930-9987-9f9ffd98c283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"SMSSpamCollection\",\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"label\", \"text\"]\n",
    ")\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66cfdf-0060-400d-9006-590d3f2ca499",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fd5ec30-927c-4192-a339-82c61e3c550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    4516\n",
      "1     653\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# give numeric labels\n",
    "df[\"label\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "print(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3982fbbd-e557-4918-9f29-5f140f9a07ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Go until jurong point, crazy.. Available only ...   \n",
      "1                      Ok lar... Joking wif u oni...   \n",
      "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
      "3  U dun say so early hor... U c already then say...   \n",
      "4  Nah I don't think he goes to usf, he lives aro...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  go until jurong point crazy available only in ...  \n",
      "1                            ok lar joking wif u oni  \n",
      "2  free entry in a wkly comp to win fa cup final ...  \n",
      "3        u dun say so early hor u c already then say  \n",
      "4  nah i don t think he goes to usf he lives arou...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()                      # lowercase\n",
    "    text = re.sub(r'\\d+', ' ', text)         # remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)     # remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)         # remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_text)\n",
    "print(df[[\"text\", \"clean_text\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78da5cf4-79d6-4b56-b75d-9f5b641ec63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# removing stopwords improves Naive Bayes performance dramatically\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in ENGLISH_STOP_WORDS]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"clean_text\"] = df[\"clean_text\"].apply(remove_stopwords)\n",
    "df_final = df[[\"clean_text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c86e9-1520-46c2-88b5-778ef9aa1ec9",
   "metadata": {},
   "source": [
    "# Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41ed6ebc-4bea-4520-8ece-472148e3e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_final[\"clean_text\"],\n",
    "    df_final[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_final[\"label\"]\n",
    ")\n",
    "\n",
    "# convert text to numerical features (for bag of words)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7562d1f7-3113-4a52-a412-f6f7862fc379",
   "metadata": {},
   "source": [
    "# Implement Naive Bayes and Bag of Words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (.venv)",
   "language": "python",
   "name": "python312_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
